{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_test = pd.read_csv('data/test.csv')\n",
    "titanic_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic = pd.read_csv('data/train.csv')\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "combined = [titanic, titanic_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General purpose helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def fit_eval_model(fit_data, features, target, prd, scoring=None):\n",
    "    \"\"\"\n",
    "        Wrapper to fit a sklearn predictor on a dataframe\n",
    "        and optionally perform a diagnostic CV run.\n",
    "        \n",
    "        - fit_data is a dataframe including an Age column.\n",
    "        - features is a list of columns in fit_data to use in\n",
    "          fitting the model, it should _not_ include Age.\n",
    "        - target is a string containing the name of the variable\n",
    "          that is to be predicted.\n",
    "        - prd is a predictor object.\n",
    "        - scoring optional, the scoring method to be used in CV\n",
    "          if not provided then CV is skipped  \n",
    "    \"\"\"\n",
    "    \n",
    "    if scoring:\n",
    "        scores = cross_val_score(prd,\n",
    "                                 fit_data.loc[:, features],\n",
    "                                 fit_data[target], \n",
    "                                 scoring=scoring,\n",
    "                                 cv=10)\n",
    "        print(\"CV {:.8}: {:0.2f} (+/- {:0.2f})\" \\\n",
    "              .format(scoring, scores.mean(), scores.std() * 2))\n",
    "\n",
    "\n",
    "    prd.fit(fit_data.loc[:, features],\n",
    "                   fit_data[target]);\n",
    "    return prd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning, Wrangling, Engineering\n",
    "\n",
    "In this section I deal with missing data and engineering new features from the columns already present in the datasets.\n",
    "\n",
    "The order of those processes is a bit of a mess because some engineered features depend on a feature with missing data that must be first imputated using other engineered features and so on.\n",
    "\n",
    "Also not all features engineered ended up being of any use, those will probably get cleaned up at a convenient time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On missing data\n",
    "\n",
    "### Training set\n",
    "* 177(~20%) of **ages** are missing. Age is expected to be a strong predictor. I should work on remedying that, [Gertlowitz](http://gertlowitz.blogspot.com.br/2013/06/where-am-i-up-to-with-titanic-competion.html) used people's titles(Ms., Mr. etc.) to predict missing ages to good measure.\n",
    "\n",
    "* 2(<1%) people are missing **embark** points. This shouldn't be too important, but my swarmplots indicated there might be something at work there.\n",
    "\n",
    "* 687(~80%) people are missing **cabin** information. I expect deck location and floor to be a reasonable predictor, but there might not be a way to reliably estimate missing data.\n",
    "\n",
    "### Test set\n",
    "* 86(~20%) are missing **ages**.\n",
    "\n",
    "* 1(<1%) is missing **fare**\n",
    "\n",
    "* 327(~80%) are missing **cabin**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the work of Gertlowitz mentioned above I extract the titles out of people's names in order to exploit it for both age and survival estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_titles (data):\n",
    "    return data['Name'].str.extract(', (\\w+).', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Title'] = get_titles(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most titles are too infrequent or not really relevant. I'm merging them into Mr, Master, Mrs and Miss as proxies for adult male, young male, adult married famale and unmarried, possibly young, female respectively. There are many models that did just fine without a  Miss/Mrs distinction however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def group_titles (row):\n",
    "    miss_titles = ['the', 'Ms', 'Mme', 'Mlle', 'Dona']\n",
    "    mrs_titles = ['Lady']\n",
    "    mr_titles = ['Jonkheer', 'Capt', 'Col', 'Don', 'Major', 'Sir', 'Rev']\n",
    "    \n",
    "    if row['Title'] in miss_titles:\n",
    "        return 'Miss'\n",
    "    elif row['Title'] in mr_titles:\n",
    "        return 'Mr'\n",
    "    elif row['Title'] in mrs_titles:\n",
    "        return 'Mrs'\n",
    "    elif row['Title'] == 'Dr':\n",
    "        if row['Sex'] == 'male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Miss'\n",
    "    else:\n",
    "        return row['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Title'] = dataset.apply(group_titles, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Deotte](https://www.kaggle.com/cdeotte/titanic-using-name-only-0-81818) did an awesome job based only on names. I decided to borrow some of his ideas on surnames and groups of passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_surnames (data):\n",
    "    return data['Name'].str.extract('^(.+),', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Surname'] = get_surnames(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing Gertlowitz did was extract the deck letter from cabin information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_deck (data):\n",
    "    return data.Cabin.str.extract('^(\\w)', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Cabin'] = dataset['Cabin'].fillna('Z')\n",
    "    dataset['Deck'] = get_deck(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family Aboard\n",
    "\n",
    "I think both Gertlowitz and Sehgal did this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_nfam (data):\n",
    "    return data.Parch + data.SibSp + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Fam'] = get_nfam(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alone\n",
    "\n",
    "Another feature due to Sehgal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_alone (fam):\n",
    "    return {True: 1, False: 0}[fam == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Alone'] = dataset.Fam.apply(get_alone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reencoding  the training set\n",
    "\n",
    "For the used categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def gen_fit_les (data):\n",
    "    \"\"\"\n",
    "    Generates a dictionary of LabelEncoders with an entry\n",
    "    for each column in data that is of type object\n",
    "    \"\"\"\n",
    "    \n",
    "    cat_cols_les = {x: LabelEncoder() \\\n",
    "                    for x in data if data[x].dtype.name == 'object'}\n",
    "\n",
    "    for item in cat_cols_les.items():\n",
    "        col = item[0]\n",
    "        le = item[1]\n",
    "        \n",
    "        le.fit(data[col])\n",
    "        \n",
    "    return cat_cols_les\n",
    "\n",
    "def les_transform (data, le_dict):\n",
    "    \"\"\"\n",
    "    Transforms data's columns with a dictionary generated by\n",
    "    gen_fit_les (above)\n",
    "    \"\"\"\n",
    "    \n",
    "    for item in le_dict.items():\n",
    "        col = item[0]\n",
    "        le = item[1]\n",
    "        \n",
    "        data[col] = le.transform(data[col])\n",
    "        \n",
    "def les_inverse_transform (data, le_dict):\n",
    "    \"\"\"\n",
    "    Inverse transforms data's columns with a dictionary generated by\n",
    "    gen_fit_les (above)\n",
    "    \"\"\"\n",
    "    \n",
    "    for item in le_dict.items():\n",
    "        col = item[0]\n",
    "        le = item[1]\n",
    "        \n",
    "        data[col] = le.inverse_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "titanic.Embarked = titanic.Embarked.fillna('U')\n",
    "\n",
    "# Because some labels are present in only one set, it's necessary\n",
    "# to train the encoders on their concatenation\n",
    "cat_cols_les = gen_fit_les(pd.concat([titanic, titanic_test]))\n",
    "les_transform(titanic, cat_cols_les)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reencoding  the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "titanic_test.Embarked = titanic_test.Embarked.fillna('U')\n",
    "\n",
    "les_transform(titanic_test, cat_cols_les)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation of fares\n",
    "\n",
    "For the one lone passenger in the test set without fare information I'm using the mean of the fares for his Pclass in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def imputate_fare(row):\n",
    "    if np.isnan(row['Fare']):\n",
    "        return titanic[titanic.Pclass == row['Pclass']] \\\n",
    "                .groupby('Ticket').mean()['Fare'].mean()\n",
    "    else:\n",
    "        return row['Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "titanic_test['Fare'] = titanic_test.apply(imputate_fare, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation of ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age imputation models are trained on the whole set of data with valid ages, spanning both the training and test sets. Is that really kosher though?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "age_features = ['Pclass', 'Parch', 'SibSp', 'Title']\n",
    "\n",
    "age_train = pd.concat([\n",
    "                        titanic[~np.isnan(titanic.Age)],\n",
    "                        titanic_test[~np.isnan(titanic_test.Age)]\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV neg_mean: -8.15 (+/- 0.94)\n"
     ]
    }
   ],
   "source": [
    "age_model = fit_eval_model(age_train, \n",
    "                            age_features,\n",
    "                            'Age',\n",
    "                            GradientBoostingRegressor(),\n",
    "                            'neg_mean_absolute_error'\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "titanic.loc[np.isnan(titanic.Age), 'Age'] = \\\n",
    "    age_model.predict(titanic[np.isnan(titanic.Age)] \\\n",
    "                       .loc[:, age_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "titanic_test.loc[np.isnan(titanic_test.Age), 'Age'] = \\\n",
    "    age_model.predict(titanic_test[np.isnan(titanic_test.Age)] \\\n",
    "                       .loc[:, age_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age*Pclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is due to [Sehgal](https://www.kaggle.com/startupsci/titanic-data-science-solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['AgePclass'] = dataset['Age'] * dataset['Pclass']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I reserve 30% of the training set in order to perform validation experiments that may or may not get pushed into the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV f1: 0.79 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "#train_features = ['Title', 'Sex', 'AgePclass', 'Fare', 'Fam', 'Ticket']\n",
    "train_features = ['Title' ,'Sex', 'AgePclass', 'Fare', 'SibSp', 'Ticket', 'Surname']\n",
    "\n",
    "train_set, test_set = train_test_split(titanic[['Survived'] + train_features],\n",
    "                                       test_size=0.3\n",
    "                                      )\n",
    "\n",
    "model = fit_eval_model(train_set, \n",
    "                       train_features,\n",
    "                       'Survived',\n",
    "                       GradientBoostingClassifier(),\n",
    "                       'f1'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[151,  22],\n",
       "       [ 23,  72]])"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_set[train_features])\n",
    "confusion_matrix(test_set['Survived'], pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the model to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(titanic_test.loc[:, train_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(titanic_test['PassengerId'])\n",
    "results['Survived'] = predictions\n",
    "results.to_csv('predictions.csv', \n",
    "                  columns=('PassengerId', 'Survived'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "486px",
    "width": "300px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
