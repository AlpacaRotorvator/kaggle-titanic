{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_test = pd.read_csv('data/test.csv')\n",
    "titanic_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic = pd.read_csv('data/train.csv')\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "combined = [titanic, titanic_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning, Wrangling, Engineering\n",
    "\n",
    "In this section I deal with missing data and engineering new features from the columns already present in the datasets.\n",
    "\n",
    "The order of those processes is a bit of a mess because some engineered features depend on a feature with missing data that must be first imputated using other engineered features and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On missing data\n",
    "\n",
    "### Training set\n",
    "* 177(~20%) of **ages** are missing. Age is expected to be a strong predictor. I should work on remedying that, [Gertlowitz](http://gertlowitz.blogspot.com.br/2013/06/where-am-i-up-to-with-titanic-competion.html) used people's titles(Ms., Mr. etc.) to predict missing ages to good measure.\n",
    "\n",
    "* 2(<1%) people are missing **embark** points. This shouldn't be too important, but my swarmplots indicated there might be something at work there.\n",
    "\n",
    "* 687(~80%) people are missing **cabin** information. I expect deck location and floor to be a reasonable predictor, but there might not be a way to reliably estimate missing data.\n",
    "\n",
    "### Test set\n",
    "* 86(~20%) are missing **ages**.\n",
    "\n",
    "* 1(<1%) is missing **fare**\n",
    "\n",
    "* 327(~80%) are missing **cabin**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the work of Gertlowitz mentioned above I extract the titles out of people's names in order to exploit it for both age and survival estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_titles (data):\n",
    "    return data['Name'].str.extract(', (\\w+).', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Title'] = get_titles(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def group_titles (row):\n",
    "    miss_titles = ['the', 'Ms', 'Mme', 'Mlle', 'Dona']\n",
    "    mrs_titles = ['Lady']\n",
    "    mr_titles = ['Jonkheer', 'Capt', 'Col', 'Don', 'Major', 'Sir', 'Rev']\n",
    "    \n",
    "    if row['Title'] in miss_titles:\n",
    "        return 'Miss'\n",
    "    elif row['Title'] in mr_titles:\n",
    "        return 'Mr'\n",
    "    elif row['Title'] in mrs_titles:\n",
    "        return 'Mrs'\n",
    "    elif row['Title'] == 'Dr':\n",
    "        if row['Sex'] == 'male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Miss'\n",
    "        \n",
    "    else:\n",
    "        return row['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Title'] = dataset.apply(group_titles, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing Gertlowitz did was extract the deck letter from cabin information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_deck (data):\n",
    "    return data.Cabin.fillna('Z').str.extract('^(\\w)', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Deck'] = get_deck(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family Aboard\n",
    "\n",
    "I think both Gertlowitz and Sehgal did this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_nfam (data):\n",
    "    return data.Parch + data.SibSp + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Fam'] = get_nfam(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alone\n",
    "\n",
    "Another feature due to Sehgal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_alone (fam):\n",
    "    return {True: 1, False: 0}[fam == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Alone'] = dataset.Fam.apply(get_alone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the used subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Title       891 non-null object\n",
      "Sex         891 non-null object\n",
      "Age         714 non-null float64\n",
      "Fam         891 non-null int64\n",
      "Ticket      891 non-null object\n",
      "Fare        891 non-null float64\n",
      "Deck        891 non-null object\n",
      "Embarked    889 non-null object\n",
      "Alone       891 non-null int64\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 76.6+ KB\n"
     ]
    }
   ],
   "source": [
    "used_features = ['Survived', 'Pclass', 'Title', 'Sex', 'Age',\n",
    "                 'Fam', 'Ticket', 'Fare', 'Deck', 'Embarked', 'Alone']\n",
    "data_train = titanic.loc[:, used_features]\n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 10 columns):\n",
      "Pclass      418 non-null int64\n",
      "Title       418 non-null object\n",
      "Sex         418 non-null object\n",
      "Age         332 non-null float64\n",
      "Fam         418 non-null int64\n",
      "Ticket      418 non-null object\n",
      "Fare        417 non-null float64\n",
      "Deck        418 non-null object\n",
      "Embarked    418 non-null object\n",
      "Alone       418 non-null int64\n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 32.7+ KB\n"
     ]
    }
   ],
   "source": [
    "test_features = list(used_features)\n",
    "test_features.remove('Survived')\n",
    "data_test = titanic_test.loc[:, test_features]\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "combined_used = [data_train, data_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reencoding  the training set\n",
    "\n",
    "For the used categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def gen_fit_les (data):\n",
    "    \"\"\"\n",
    "    Generates a dictionary of LabelEncoders with an entry\n",
    "    for each column in data that is of type object\n",
    "    \"\"\"\n",
    "    \n",
    "    cat_cols_les = { x: LabelEncoder() \\\n",
    "                    for x in data if data[x].dtype.name == 'object'}\n",
    "\n",
    "    for item in cat_cols_les.items():\n",
    "        col = item[0]\n",
    "        le = item[1]\n",
    "        \n",
    "        le.fit(data[col])\n",
    "        \n",
    "    return cat_cols_les\n",
    "\n",
    "def les_transform (data, le_dict):\n",
    "    \"\"\"\n",
    "    Transform data's columns with a dictionary generated by\n",
    "    gen_fit_les (above)\n",
    "    \"\"\"\n",
    "    \n",
    "    for item in le_dict.items():\n",
    "        col = item[0]\n",
    "        le = item[1]\n",
    "        \n",
    "        data[col] = le.transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "data_train.Embarked = data_train.Embarked.fillna('U')\n",
    "\n",
    "# Because some labels are present in only one set, it's necessary\n",
    "# to train the encoders on their concatenation\n",
    "cat_cols_les = gen_fit_les(pd.concat([data_train, data_test]))\n",
    "les_transform(data_train, cat_cols_les)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reencoding  the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "data_test.Embarked = data_test.Embarked.fillna('U')\n",
    "\n",
    "les_transform(data_test, cat_cols_les)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation of fares\n",
    "\n",
    "For the one lone passenger in the test set without fare information I'm using the mean of the fares for his Pclass in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def imputate_fare(row):\n",
    "    if np.isnan(row['Fare']):\n",
    "        return titanic[titanic.Pclass == row['Pclass']] \\\n",
    "                .groupby('Ticket').mean()['Fare'].mean()\n",
    "    else:\n",
    "        return row['Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "data_test['Fare'] = data_test.apply(imputate_fare, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation of ages\n",
    "\n",
    "Experimental imputation using a regression forest, because computation is cheap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.31 (+/- 0.21)\n"
     ]
    }
   ],
   "source": [
    "age_features = ['Pclass', 'Title', 'Fam', 'Ticket', 'Fare']\n",
    "\n",
    "age_forest = RandomForestRegressor(n_jobs=-1)\n",
    "\n",
    "# Is this really kosher?\n",
    "age_train = pd.concat([\n",
    "                        data_train[~np.isnan(data_train.Age)],\n",
    "                        data_test[~np.isnan(data_test.Age)]\n",
    "                      ])\n",
    "\n",
    "scores = cross_val_score(age_forest,\n",
    "                         age_train.loc[:, age_features],\n",
    "                         age_train['Age'], \n",
    "                         cv=10)\n",
    "print(\"CV Accuracy: {:0.2f} (+/- {:0.2f})\" \\\n",
    "      .format(scores.mean(), scores.std() * 2))\n",
    "\n",
    "\n",
    "age_forest.fit(age_train.loc[:, age_features],\n",
    "               age_train['Age']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "data_train.loc[np.isnan(titanic.Age), 'Age'] = \\\n",
    "    age_forest.predict(data_train[np.isnan(titanic.Age)] \\\n",
    "                       .loc[:, age_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "data_test.loc[np.isnan(titanic_test.Age), 'Age'] = \\\n",
    "    age_forest.predict(data_test[np.isnan(titanic_test.Age)] \\\n",
    "                       .loc[:, age_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age*Pclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is due to [Sehgal](https://www.kaggle.com/startupsci/titanic-data-science-solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "used_features.remove('Age')\n",
    "used_features.remove('Pclass')\n",
    "used_features.append('AgePclass')\n",
    "\n",
    "for dataset in combined_used:\n",
    "    dataset['AgePclass'] = dataset['Age'] * dataset['Pclass']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest classifier, just to get things going:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.83 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "train_features = list(used_features)\n",
    "train_features.remove('Survived')\n",
    "train_features = ['Title', 'Sex', 'AgePclass', 'Fare', 'Ticket', 'Alone']\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "                               n_jobs=-1\n",
    "                              )\n",
    "model.fit(data_train.loc[:, train_features], data_train['Survived'])\n",
    "#model.score(test.iloc[:, 1:], test['Survived'])\n",
    "scores = cross_val_score(model, \n",
    "                         data_train.iloc[:, 1:], \n",
    "                         data_train['Survived'], \n",
    "                         cv=10,\n",
    "                         n_jobs=-1\n",
    "                        )\n",
    "print(\"CV Accuracy: {:0.2f} (+/- {:0.2f})\" \\\n",
    "      .format(scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the model to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(data_test.loc[:, train_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(titanic_test['PassengerId'])\n",
    "results['Survived'] = predictions\n",
    "results.to_csv('predictions.csv', \n",
    "                  columns=('PassengerId', 'Survived'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pclass', 0.1304445892664015),\n",
       " ('Title', 0.25744065637321223),\n",
       " ('Fam', 0.11672885355080706),\n",
       " ('Ticket', 0.30182037746726315),\n",
       " ('Fare', 0.19356552334231608)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*zip(age_features, age_forest.feature_importances_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Title', 0.09912321892544149),\n",
       " ('Sex', 0.17509023040807634),\n",
       " ('AgePclass', 0.2649289012184134),\n",
       " ('Fare', 0.19375925465290028),\n",
       " ('Ticket', 0.24579442631515702),\n",
       " ('Alone', 0.021303968480011558)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*zip(train_features, model.feature_importances_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "252px",
    "width": "235px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
