{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_test = pd.read_csv('data/test.csv')\n",
    "titanic_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic = pd.read_csv('data/train.csv')\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "combined = [titanic, titanic_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General purpose helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def fit_eval_model(fit_data, features, target, prd, scoring=None):\n",
    "    \"\"\"\n",
    "        Wrapper to fit a sklearn predictor on a dataframe\n",
    "        and optionally perform a diagnostic CV run.\n",
    "        \n",
    "        - fit_data is a dataframe including an Age column.\n",
    "        - features is a list of columns in fit_data to use in\n",
    "          fitting the model, it should _not_ include Age.\n",
    "        - target is a string containing the name of the variable\n",
    "          that is to be predicted.\n",
    "        - prd is a predictor object.\n",
    "        - scoring optional, the scoring method to be used in CV\n",
    "          if not provided then CV is skipped  \n",
    "    \"\"\"\n",
    "    \n",
    "    if scoring:\n",
    "        scores = cross_val_score(prd,\n",
    "                                 fit_data.loc[:, features],\n",
    "                                 fit_data[target], \n",
    "                                 scoring=scoring,\n",
    "                                 cv=10)\n",
    "        print(\"CV {:.8}: {:0.2f} (+/- {:0.2f})\" \\\n",
    "              .format(scoring, scores.mean(), scores.std() * 2))\n",
    "\n",
    "\n",
    "    prd.fit(fit_data.loc[:, features],\n",
    "                   fit_data[target]);\n",
    "    return prd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning, Wrangling, Engineering\n",
    "\n",
    "In this section I deal with missing data and engineering new features from the columns already present in the datasets.\n",
    "\n",
    "The order of those processes is a bit of a mess because some engineered features depend on a feature with missing data that must be first imputated using other engineered features and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On missing data\n",
    "\n",
    "### Training set\n",
    "* 177(~20%) of **ages** are missing. Age is expected to be a strong predictor. I should work on remedying that, [Gertlowitz](http://gertlowitz.blogspot.com.br/2013/06/where-am-i-up-to-with-titanic-competion.html) used people's titles(Ms., Mr. etc.) to predict missing ages to good measure.\n",
    "\n",
    "* 2(<1%) people are missing **embark** points. This shouldn't be too important, but my swarmplots indicated there might be something at work there.\n",
    "\n",
    "* 687(~80%) people are missing **cabin** information. I expect deck location and floor to be a reasonable predictor, but there might not be a way to reliably estimate missing data.\n",
    "\n",
    "### Test set\n",
    "* 86(~20%) are missing **ages**.\n",
    "\n",
    "* 1(<1%) is missing **fare**\n",
    "\n",
    "* 327(~80%) are missing **cabin**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the work of Gertlowitz mentioned above I extract the titles out of people's names in order to exploit it for both age and survival estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_titles (data):\n",
    "    return data['Name'].str.extract(', (\\w+).', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Title'] = get_titles(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def group_titles (row):\n",
    "    miss_titles = ['the', 'Ms', 'Mme', 'Mlle', 'Dona']\n",
    "    mrs_titles = ['Lady']\n",
    "    mr_titles = ['Jonkheer', 'Capt', 'Col', 'Don', 'Major', 'Sir', 'Rev']\n",
    "    \n",
    "    if row['Title'] in miss_titles:\n",
    "        return 'Miss'\n",
    "    elif row['Title'] in mr_titles:\n",
    "        return 'Mr'\n",
    "    elif row['Title'] in mrs_titles:\n",
    "        return 'Mrs'\n",
    "    elif row['Title'] == 'Dr':\n",
    "        if row['Sex'] == 'male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Miss'\n",
    "        \n",
    "    else:\n",
    "        return row['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Title'] = dataset.apply(group_titles, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing Gertlowitz did was extract the deck letter from cabin information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_deck (data):\n",
    "    return data.Cabin.str.extract('^(\\w)', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Cabin'] = dataset['Cabin'].fillna('Z')\n",
    "    dataset['Deck'] = get_deck(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family Aboard\n",
    "\n",
    "I think both Gertlowitz and Sehgal did this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_nfam (data):\n",
    "    return data.Parch + data.SibSp + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Fam'] = get_nfam(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alone\n",
    "\n",
    "Another feature due to Sehgal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_alone (fam):\n",
    "    return {True: 1, False: 0}[fam == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['Alone'] = dataset.Fam.apply(get_alone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reencoding  the training set\n",
    "\n",
    "For the used categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def gen_fit_les (data):\n",
    "    \"\"\"\n",
    "    Generates a dictionary of LabelEncoders with an entry\n",
    "    for each column in data that is of type object\n",
    "    \"\"\"\n",
    "    \n",
    "    cat_cols_les = {x: LabelEncoder() \\\n",
    "                    for x in data if data[x].dtype.name == 'object'}\n",
    "\n",
    "    for item in cat_cols_les.items():\n",
    "        col = item[0]\n",
    "        le = item[1]\n",
    "        \n",
    "        le.fit(data[col])\n",
    "        \n",
    "    return cat_cols_les\n",
    "\n",
    "def les_transform (data, le_dict):\n",
    "    \"\"\"\n",
    "    Transform data's columns with a dictionary generated by\n",
    "    gen_fit_les (above)\n",
    "    \"\"\"\n",
    "    \n",
    "    for item in le_dict.items():\n",
    "        col = item[0]\n",
    "        le = item[1]\n",
    "        \n",
    "        data[col] = le.transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "titanic.Embarked = titanic.Embarked.fillna('U')\n",
    "\n",
    "# Because some labels are present in only one set, it's necessary\n",
    "# to train the encoders on their concatenation\n",
    "cat_cols_les = gen_fit_les(pd.concat([titanic, titanic_test]))\n",
    "les_transform(titanic, cat_cols_les)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reencoding  the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "titanic_test.Embarked = titanic_test.Embarked.fillna('U')\n",
    "\n",
    "les_transform(titanic_test, cat_cols_les)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation of fares\n",
    "\n",
    "For the one lone passenger in the test set without fare information I'm using the mean of the fares for his Pclass in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def imputate_fare(row):\n",
    "    if np.isnan(row['Fare']):\n",
    "        return titanic[titanic.Pclass == row['Pclass']] \\\n",
    "                .groupby('Ticket').mean()['Fare'].mean()\n",
    "    else:\n",
    "        return row['Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "titanic_test['Fare'] = titanic_test.apply(imputate_fare, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation of ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age imputation models are trained on the whole set of data with valid ages, spanning both the training and test sets. Is that really kosher though?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "age_features = ['Pclass', 'Title', 'Fam', 'Fare']\n",
    "\n",
    "age_train = pd.concat([\n",
    "                        titanic[~np.isnan(titanic.Age)],\n",
    "                        titanic_test[~np.isnan(titanic_test.Age)]\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV neg_mean: -8.42 (+/- 1.24)\n"
     ]
    }
   ],
   "source": [
    "age_model = fit_eval_model(age_train, \n",
    "                            age_features,\n",
    "                            'Age',\n",
    "                            GradientBoostingRegressor(),\n",
    "                            'neg_mean_absolute_error'\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "titanic.loc[np.isnan(titanic.Age), 'Age'] = \\\n",
    "    age_model.predict(titanic[np.isnan(titanic.Age)] \\\n",
    "                       .loc[:, age_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "titanic_test.loc[np.isnan(titanic_test.Age), 'Age'] = \\\n",
    "    age_model.predict(titanic_test[np.isnan(titanic_test.Age)] \\\n",
    "                       .loc[:, age_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age*Pclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is due to [Sehgal](https://www.kaggle.com/startupsci/titanic-data-science-solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "for dataset in combined:\n",
    "    dataset['AgePclass'] = dataset['Age'] * dataset['Pclass']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest classifier, just to get things going:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV f1: 0.75 (+/- 0.13)\n"
     ]
    }
   ],
   "source": [
    "train_features = ['Title', 'Sex', 'AgePclass', 'Fare', 'Alone']\n",
    "\n",
    "model = fit_eval_model(titanic, \n",
    "                       train_features,\n",
    "                       'Survived',\n",
    "                       GradientBoostingClassifier(),\n",
    "                       'f1'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the model to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(titanic_test.loc[:, train_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(titanic_test['PassengerId'])\n",
    "results['Survived'] = predictions\n",
    "results.to_csv('predictions.csv', \n",
    "                  columns=('PassengerId', 'Survived'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments and stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importances for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pclass', 0.08876489124030235),\n",
       " ('Title', 0.17801058000031905),\n",
       " ('Fam', 0.14308991027674106),\n",
       " ('Fare', 0.5901346184826379)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*zip(age_features, age_model.feature_importances_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Title', 0.04633956606755527),\n",
       " ('Sex', 0.13003513934511465),\n",
       " ('AgePclass', 0.3226937624908486),\n",
       " ('Fare', 0.4622930621134703),\n",
       " ('Alone', 0.03863846998301115)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*zip(train_features, model.feature_importances_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For age imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_age_model (reg):\n",
    "    fit_eval_model(age_train, \n",
    "                   age_features, \n",
    "                   'Age',\n",
    "                   reg,\n",
    "                   'neg_mean_absolute_error'\n",
    "                  )\n",
    "    \n",
    "def fit_age_model_multi (reg_list):\n",
    "    for reg in reg_list:\n",
    "        fit_age_model(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV neg_mean: -8.88 (+/- 0.82)\n",
      "CV neg_mean: -9.72 (+/- 1.40)\n",
      "CV neg_mean: -8.92 (+/- 1.60)\n",
      "CV neg_mean: -10.13 (+/- 0.81)\n",
      "CV neg_mean: -9.77 (+/- 1.10)\n",
      "CV neg_mean: -8.42 (+/- 1.25)\n",
      "CV neg_mean: -9.37 (+/- 1.41)\n"
     ]
    }
   ],
   "source": [
    "model_list = [\n",
    "              linear_model.LinearRegression(n_jobs=-1),\n",
    "              DecisionTreeRegressor(),\n",
    "              RandomForestRegressor(n_jobs=-1),\n",
    "              svm.SVR(),\n",
    "              neighbors.KNeighborsRegressor(n_jobs=-1),\n",
    "              GradientBoostingRegressor(),\n",
    "              ExtraTreesRegressor(n_jobs=-1),\n",
    "]\n",
    "\n",
    "fit_age_model_multi(model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to a simple model that just assigns the median age of each title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.574885277246654"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = age_train.groupby('Title').median()\n",
    "\n",
    "title_age_dict = {x: y for x,y in zip(a.index, a.Age)}\n",
    "\n",
    "mae = 0\n",
    "for idx, row in age_train.iterrows():\n",
    "    mae += np.abs(title_age_dict[row['Title']] - row['Age'])\n",
    "\n",
    "-mae / age_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this:\n",
    "* Most models seem to be equivalent under pairwise Welch t-tests.\n",
    "* However I don't trust statistics and will favour Linear, RF and GBRT for further tuning, since they can perform better than the median model under best conditions.\n",
    "* Most of the time a one-sample t-test can't distinguish between the median-based model and the RF model, but the GBRT and Linear models usually let me discard the null hypothesis.\n",
    "* Ridge will probably be used as a surrogate for linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_search = GridSearchCV(RandomForestRegressor(),\n",
    "                         {\n",
    "                             'criterion': ['mse', 'mae'],\n",
    "                             'min_samples_split': [2, 4, 8, 16],\n",
    "                             'min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "                             'n_estimators': [4, 8, 10, 16, 25]\n",
    "                         },\n",
    "                         n_jobs=-1\n",
    "                        )\n",
    "rf_search.fit(age_train.loc[:, age_features], age_train['Age']);\n",
    "\n",
    "rf_best = rf_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV neg_mean: -8.47 (+/- 1.15)\n"
     ]
    }
   ],
   "source": [
    "fit_age_model(rf_best);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_search = GridSearchCV(GradientBoostingRegressor(),\n",
    "                          {\n",
    "                             'loss': ['ls', 'lad', 'huber'],\n",
    "                             'min_samples_split': [2, 4, 8, 16],\n",
    "                             'min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "                             'max_depth': [2, 3, 4, 5],\n",
    "                             'n_estimators': [16, 64, 128, 256]\n",
    "                          },\n",
    "                          n_jobs=-1\n",
    "                        )\n",
    "gbt_search.fit(age_train.loc[:, age_features], age_train['Age']);\n",
    "\n",
    "gbt_best = gbt_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_age_model(gbt_best);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tl;dr either I chose the grid very badly or hyperparameter tuning is of little help here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "252px",
    "width": "235px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
